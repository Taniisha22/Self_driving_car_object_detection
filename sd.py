# -*- coding: utf-8 -*-
"""SD.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1j1QR3nalRnUOHeoLfyxy2Ahy-P4GA_U7
"""

mkdir TensorFlow

cd /content/TensorFlow

!mkdir scripts
!mkdir workspace

pwd



# Commented out IPython magic to ensure Python compatibility.
# %%bash
# cd scripts 
# mkdir preprocessing

# Commented out IPython magic to ensure Python compatibility.
# %%bash
# cd workspace
# mkdir training_demo
# cd training_demo
# mkdir annotations
# mkdir models
# mkdir exported-models
# mkdir images
# mkdir pre-trained-models
# cd images
# mkdir train
# mkdir test

# Commented out IPython magic to ensure Python compatibility.
# #download generate.py file to convert imgs into tfrec format
# %%bash 
# cd /content/TensorFlow/scripts/preprocessing/
# curl -o generate_tfrecord.py https://raw.githubusercontent.com/sglvladi/TensorFlowObjectDetectionTutorial/master/docs/source/scripts/generate_tfrecord.py
# #curl -o partition_dataset.py https://drive.google.com/file/d/1YvFSF1D8h6L3T8P5V9M4s7IoBCcKUXIS/view?usp=sharing

# Commented out IPython magic to ensure Python compatibility.
# #Download pretrained dataset
# %%bash 
# cd /content/TensorFlow/workspace/training_demo/pre-trained-models/
# curl -o ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8.tar.gz http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8.tar.gz

# Commented out IPython magic to ensure Python compatibility.
# #Extract pretrained dataset
# %%bash
# cd /content/TensorFlow/workspace/training_demo/pre-trained-models/
# tar -xvzf ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8.tar.gz

# Commented out IPython magic to ensure Python compatibility.
# %%bash
# cd /content/TensorFlow/workspace/training_demo/models
# mkdir my_ssd_mobilenet_v1_fpn
# cd ..
# cp -v pre-trained-models/ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/pipeline.config  models/my_ssd_mobilenet_v1_fpn/pipeline.config

#Step 4- Mount Google Drive.

from google.colab import drive
drive.mount('/content/gdrive')

# Commented out IPython magic to ensure Python compatibility.
#Step 5- Download TensorFlow Model Garden.

#cd into the TensorFlow directory in your Google Drive
# %cd '/content/TensorFlow'

#and clone the TensorFlow Model Garden repository
!git clone https://github.com/tensorflow/models.git

#using a older version of repo (21 Sept 2020)
# %cd '/content/TensorFlow/models'
!git checkout -f e04dafd04d69053d3733bb91d47d0d95bc2c8199

#Step 6- Install some required libraries and tools.

!apt-get install protobuf-compiler python-lxml python-pil
!pip install Cython pandas tf-slim lvis

# Commented out IPython magic to ensure Python compatibility.
#Step 7- Compile the Protobuf libraries.

#cd into 'TensorFlow/models/research'
# %cd '/content/TensorFlow/models/research/'
!protoc object_detection/protos/*.proto --python_out=.
!cp object_detection/packages/tf2/setup.py .

#Step 8- Set the environment.

import os
import sys
!pip install tensorflow==2.7
os.environ['PYTHONPATH']+=":/content/TensorFlow/models"
sys.path.append("/content/TensorFlow/models/research")

# Commented out IPython magic to ensure Python compatibility.
#Step 9- Build and Install setup.py.
# %cd /content/TensorFlow/models/research
!python setup.py build
!python setup.py install

# Commented out IPython magic to ensure Python compatibility.
#Step 10- Test the installation.

#cd into 'TensorFlow/models/research/object_detection/builders/'
# %cd '/content/TensorFlow/models/research/object_detection/builders/'
!python model_builder_tf2_test.py
from object_detection.utils import label_map_util
from object_detection.utils import visualization_utils as viz_utils
print('Done')

# Commented out IPython magic to ensure Python compatibility.
# %%bash
# cd /content/TensorFlow/
# cp -v models/research/object_detection/model_main_tf2.py workspace/training_demo/model_main_tf2.py
# cp -v models/research/object_detection/exporter_main_v2.py workspace/training_demo/exporter_main_v2.py

#Mount Google Drive.

from google.colab import drive
drive.mount('/content/gdrive')
drive.mount("/content/gdrive", force_remount=True)

# Commented out IPython magic to ensure Python compatibility.
# %%bash
# cp -r /content/gdrive/MyDrive/Auto_Object_Detection/images/train /content/TensorFlow/workspace/training_demo/images
# cp -r /content/gdrive/MyDrive/Auto_Object_Detection/images/test /content/TensorFlow/workspace/training_demo/images

# Commented out IPython magic to ensure Python compatibility.
#Step 12- Generate TFrecords.

#cd into preprocessing directory
# %cd '/content/TensorFlow/scripts/preprocessing'
#run the cell to generate test.record and train.record
!python generate_tfrecord.py -x '/content/TensorFlow/workspace/training_demo/images/train' -l '/content/TensorFlow/workspace/training_demo/annotations/label_map.pbtxt' -o '/content/TensorFlow/workspace/training_demo/annotations/train.record'
!python generate_tfrecord.py -x '/content/TensorFlow/workspace/training_demo/images/test' -l '/content/TensorFlow/workspace/training_demo/annotations/label_map.pbtxt' -o '/content/TensorFlow/workspace/training_demo/annotations/test.record'

# !python generate_tfrecord.py -x '[path_to_train_folder]' -l '[path_to_annotations_folder]/label_map.pbtxt' -o '[path_to_annotations_folder]/train.record'
# !python generate_tfrecord.py -x '[path_to_test_folder]' -l '[path_to_annotations_folder]/label_map.pbtxt' -o '[path_to_annotations_folder]/test.record'



# Commented out IPython magic to ensure Python compatibility.
#Step 14- Start Tensorboard.

#cd into training_demo
# %cd '/content/TensorFlow/workspace/training_demo'

#start the Tensorboard
# %reload_ext tensorboard
# %tensorboard --logdir=models/my_ssd_mobilenet_v1_fpn

# %load_ext tensorboard
# %tensorboard --logdir=models/[name_of_pre-trained-model_you_downloaded]



# Commented out IPython magic to ensure Python compatibility.
#@title Default title text
#Step 15- Train the model.
# %cd '/content/TensorFlow/workspace/training_demo'
#run the cell to start model training 
!python model_main_tf2.py --model_dir=models/my_ssd_mobilenet_v1_fpn --pipeline_config_path=models/my_ssd_mobilenet_v1_fpn/pipeline.config

#!python model_main_tf2.py --model_dir=models/[name_of_pre-trained-model_you_downloaded] --pipeline_config_path=models/[name_of_pre-trained-model_you_downloaded]/pipeline.config

#Step 16- Export the Trained Model.
#run the cell to start model training
!python exporter_main_v2.py --input_type image_tensor --pipeline_config_path ./models/my_ssd_mobilenet_v1_fpn/pipeline.config --trained_checkpoint_dir ./models/my_ssd_mobilenet_v1_fpn/ --output_directory ./exported-models/my_model

#Step 17- Test the Model.

#Loading the saved_model
import tensorflow as tf
import time
from object_detection.utils import label_map_util
from object_detection.utils import visualization_utils as viz_utils

PATH_TO_SAVED_MODEL="/content/TensorFlow/workspace/training_demo/exported-models/my_model/saved_model"

print('Loading model...', end='')

# Load saved model and build the detection function
detect_fn=tf.saved_model.load(PATH_TO_SAVED_MODEL)

print('Done!')

#Step 18- Testing the Model.

#Loading the label_map
category_index=label_map_util.create_category_index_from_labelmap("/content/TensorFlow/workspace/training_demo/annotations/label_map.pbtxt",use_display_name=True)

#category_index=label_map_util.create_category_index_from_labelmap([path_to_label_map],use_display_name=True)

#Step 19- Testing the Model.
#download imag for testing
#curl -o test.jpg https://images.thestar.com/FOfRxDY5GE4eTKn_ahGMn1CkWEo=/1200x798/smart/filters:cb(2700061000)/https://www.thestar.com/content/dam/thestar/life/food_wine/2013/11/04/apples_oranges_or_bananas_which_fruit_is_nutritionally_the_best/apple_orange_banana.jpg

#Loading the image

img=['/content/TensorFlow/workspace/training_demo/images/test/259ff749ac781352_jpg.rf.8acc4aba3916d2dd58c3acca8890194b.jpg',
     '/content/TensorFlow/workspace/training_demo/images/test/00e9be89-00000110_jpg.rf.0c42980478f0ee70af8203c9bb03bb88.jpg',
     '/content/TensorFlow/workspace/training_demo/images/test/00e9be89-00001015_jpg.rf.048ae1d8b77bca9effd4488deaab83c4.jpg',
     '/content/TensorFlow/workspace/training_demo/images/test/00e9be89-00000135_jpg.rf.206eb546f39d12790ba166303d0ba276.jpg',
     '/content/TensorFlow/workspace/training_demo/images/test/00e9be89-00000125_jpg.rf.988c68e05492ebb12456973b955e9447.jpg',
     '/content/TensorFlow/workspace/training_demo/images/test/61b330a7098fba8b_jpg.rf.PvkjLyR5FqHNWALMC9tR.jpg',
     '/content/TensorFlow/workspace/training_demo/images/test/f00ec0093e986e99_jpg.rf.788065bc895796a1b381a68bb709d678.jpg'
     

     ]
print(img)
     

#list containing paths of all the images

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')

def load_image_into_numpy_array(path):
    return np.array(Image.open(path))

for image_path in img:
    print('Running inference for {}... '.format(image_path), end='')
    image_np=load_image_into_numpy_array(image_path)
    input_tensor=tf.convert_to_tensor(image_np)
    input_tensor=input_tensor[tf.newaxis, ...]
    detections=detect_fn(input_tensor)
    num_detections=int(detections.pop('num_detections'))
    detections={key:value[0,:num_detections].numpy()
                   for key,value in detections.items()}
    detections['num_detections']=num_detections
    detections['detection_classes']=detections['detection_classes'].astype(np.int64)
    image_np_with_detections=image_np.copy()
    viz_utils.visualize_boxes_and_labels_on_image_array(
          image_np_with_detections,
          detections['detection_boxes'],
          detections['detection_classes'],
          detections['detection_scores'],
          category_index,
          use_normalized_coordinates=True,
          max_boxes_to_draw=100,     
          min_score_thresh=.8,#0.0001      
          agnostic_mode=False)
#     %matplotlib inline
    plt.figure()
    plt.imshow(image_np_with_detections)
    print('Done')
    plt.axis('off')
    plt.show()